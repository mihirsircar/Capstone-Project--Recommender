{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPSTONE PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset used can be found at :\n",
    "https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Step: Imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy\n",
    "import scipy.optimize\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "from nltk.stem.porter import PorterStemmer # Stemming\n",
    "path='amazon_reviews_us_Musical_Instruments_v1_00.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Processing\n",
    "\n",
    "### Reading the data and filling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'marketplace': 'US',\n",
       " 'customer_id': '45610553',\n",
       " 'review_id': 'RMDCHWD0Y5OZ9',\n",
       " 'product_id': 'B00HH62VB6',\n",
       " 'product_parent': '618218723',\n",
       " 'product_title': 'AGPtekÂ® 10 Isolated Output 9V 12V 18V Guitar Pedal Board Power Supply Effect Pedals with Isolated Short Cricuit / Overcurrent Protection',\n",
       " 'product_category': 'Musical Instruments',\n",
       " 'star_rating': 3,\n",
       " 'helpful_votes': 0,\n",
       " 'total_votes': 1,\n",
       " 'vine': 'N',\n",
       " 'verified_purchase': False,\n",
       " 'review_headline': 'Three Stars',\n",
       " 'review_body': 'Works very good, but induces ALOT of noise.',\n",
       " 'review_date': '2015-08-31'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(path, 'rt', encoding=\"utf8\")\n",
    "\n",
    "header = f.readline()\n",
    "header = header.strip().split('\\t')\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for line in f:\n",
    "    fields = line.strip().split('\\t')\n",
    "    d = dict(zip(header, fields))\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    d['helpful_votes'] = int(d['helpful_votes'])\n",
    "    d['total_votes'] = int(d['total_votes'])\n",
    "    d['verified_purchase'] = d['verified_purchase'] == 'Y'\n",
    "    dataset.append(d)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into a Training and Testing set\n",
    "Training set is 80% and Testing Set is 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "723812 180953\n"
     ]
    }
   ],
   "source": [
    "N=len(dataset)\n",
    "trainingSet=dataset[:(N*4)//5]\n",
    "testSet=dataset[(N*4)//5:]\n",
    "print(len(trainingSet), len(testSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Basic Statistics\n",
    "\n",
    "1. How many entries are in your dataset?\n",
    "2. Pick a non-trivial attribute (i.e. verified purchases in example), what percentage of your data has this atttribute?\n",
    "3. Pick another different non-trivial attribute, what percentage of your data share both attributes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of entries in dataset are  723812\n",
      "Percentage of data shared by verified purchase attribute is 89.73531801075417 %\n",
      "Percentage of data shared by verified purchase and star rating attributes is 58.287649279094566 %\n"
     ]
    }
   ],
   "source": [
    "N1=(len(trainingSet))\n",
    "print('No. of entries in dataset are ',len(trainingSet))\n",
    "c=0\n",
    "for i in trainingSet:\n",
    "    if i['verified_purchase']==True:\n",
    "        c=c+1\n",
    "print('Percentage of data shared by verified purchase attribute is',(c/N1)*100,'%')\n",
    "c1=0 \n",
    "for i in trainingSet:\n",
    "    if (i['star_rating']==5) and (i['verified_purchase']==True):\n",
    "        c1=c1+1\n",
    "print('Percentage of data shared by verified purchase and star rating attributes is',(c1/N1*100),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Classification\n",
    "\n",
    "Next knowledge of classification to extract features and make predictions based on them. Here you will be using a Logistic Regression Model, keep this in mind so you know where to get help from.\n",
    "\n",
    "### Define the feature function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIX THIS\n",
    "\n",
    "def feature(d):\n",
    "    feat = [1, d['star_rating'], len(d['review_body']),d['verified_purchase']]\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "\n",
    "1. Create your __Feature Vector__ based on your feature function defined above. \n",
    "2. Create your __Label Vector__ based on the \"verified purchase\" column of your training set.\n",
    "3. Define your model as a __Logistic Regression__ model.\n",
    "4. Fit your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "data = [feature(d) for d in trainingSet]\n",
    "x_train= [values[:-1] for values in data]\n",
    "y_train= [values[-1] for values in data]\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "data1 = [feature(d) for d in testSet]\n",
    "x_test= [values[:-1] for values in data1]\n",
    "y_test= [values[-1] for values in data1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Accuracy of the Model\n",
    "\n",
    "1. Make __Predictions__ based on your model.\n",
    "2. Compute the __Accuracy__ of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this model is 0.897169430736158\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "predictionsTrain = model.predict(x_train)\n",
    "predictionsTest = model.predict(x_test)\n",
    "\n",
    "correctPredictionsTrain = predictionsTrain == y_train\n",
    "correctPredictionsTest = predictionsTest == y_test\n",
    "\n",
    "print('Accuracy for this model is',sum(correctPredictionsTrain) / len(correctPredictionsTrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Regression\n",
    "\n",
    "In this section you will start by working though two examples of altering features to further differentiate. Then you will work through how to evaluate a Regularaized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE PATH\n",
    "path = 'amazon_reviews_us_Musical_Instruments_v1_00.tsv'\n",
    "\n",
    "#GIVEN\n",
    "f = open(path, 'rt', encoding=\"utf8\")\n",
    "header = f.readline()\n",
    "header = header.strip().split('\\t')\n",
    "reg_dataset = []\n",
    "for line in f:\n",
    "    fields = line.strip().split('\\t')\n",
    "    d = dict(zip(header, fields))\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    reg_dataset.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Words in a Sample Set\n",
    "\n",
    "We are going to work with a new dataset here, as such we are going to take a smaller portion of the set and call it a Sample Set. This is because stemming on the normal training set will take a very long time. (Feel free to change sampleSet -> reg_dataset if you would like to see the difference for yourself)\n",
    "\n",
    "1. Count the number of unique words found within the 'review body' portion of the sample set defined below, making sure to __Ignore Punctuation and Capitalization__.\n",
    "2. Count the number of unique words found within the 'review body' portion of the sample set defined below, this time with use of __Stemming,__ __Ignoring Puctuation,__ ___and___ __Capitalization__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GIVEN for 1.\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "#GIVEN for 2.\n",
    "wordCountStem = defaultdict(int)\n",
    "stemmer = PorterStemmer() #use stemmer.stem(stuff)\n",
    "\n",
    "#SampleSet and y vector given\n",
    "sampleSet = reg_dataset[:2*len(reg_dataset)//10]\n",
    "y_reg = [d['star_rating'] for d in sampleSet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101381\n",
      "83875\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "for d in sampleSet:\n",
    "    r = ''.join([c for c in d['review_body'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "print(len(wordCount))\n",
    "\n",
    "for d in sampleSet:\n",
    "    r1 = ''.join([c for c in d['review_body'].lower() if not c in punctuation])\n",
    "    for w1 in r1.split():\n",
    "        w1 = stemmer.stem(w1) # with stemming\n",
    "        wordCountStem[w1] += 1\n",
    "\n",
    "print(len(wordCountStem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Classifiers\n",
    "\n",
    "1. Given the feature function and your counts vector, __Define__ your X_reg vector. (This being the X vector, simply labeled for the Regression model)\n",
    "2. __Fit__ your model using a __Ridge Model__ with (alpha = 1.0, fit_intercept = True).\n",
    "3. Using your model, __Make your Predictions__.\n",
    "4. Find the __MSE__ between your predictions and your y_reg vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GIVEN FUNCTIONS\n",
    "def feature_reg(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['review_body'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in wordSet:\n",
    "            feat[wordId[w]] += 1\n",
    "    return feat\n",
    "\n",
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)\n",
    "\n",
    "#GIVEN COUNTS AND SETS\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "#Note: increasing the size of the dictionary may require a lot of memory\n",
    "words = [x[1] for x in counts[:100]]\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error of the model is 1.2041184392177315\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "x_reg = [feature_reg(d) for d in sampleSet]\n",
    "model = linear_model.Ridge(1.0, fit_intercept=True)\n",
    "model.fit(x_reg,y_reg )\n",
    "predictions = model.predict(x_reg)\n",
    "print('Mean squared error of the model is',MSE(predictions,y_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Recommendation Systems\n",
    "\n",
    "For your final task, you will use your knowledge of simple similarity-based recommender systems to make calculate the most similar items.\n",
    "\n",
    "The next cell contains some starter code that you will need for your tasks in this section.\n",
    "Notice you should be back to using your __trainingSet__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GIVEN\n",
    "reviewsPerUser = defaultdict(set)\n",
    "reviewsPerItem = defaultdict(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Fill the Dictionaries\n",
    "\n",
    "1. For each entry in your training set, fill your default dictionaries (defined above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "itemNames={}\n",
    "for d in trainingSet:\n",
    "    user,item = d['customer_id'], d['product_id']\n",
    "    reviewsPerUser[user].add(item)\n",
    "    reviewsPerItem[item].add(user)\n",
    "    itemNames[item] = d['product_title']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GIVEN\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom\n",
    "\n",
    "def mostSimilar(iD, n):\n",
    "    similarities = []\n",
    "    users = reviewsPerItem[iD]\n",
    "    for i2 in reviewsPerItem:\n",
    "        if i2 == iD: continue\n",
    "        sim = Jaccard(users, reviewsPerItem[i2])\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the Dictionaries\n",
    "\n",
    "1. Calculate the __10__ most similar entries to the __first__ entry in your dataset, using the functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.024193548387096774, 'B000Y60NFC'),\n",
       " (0.02158273381294964, 'B007L0CH8K'),\n",
       " (0.019417475728155338, 'B0002GYX5K'),\n",
       " (0.018018018018018018, 'B00DT59450'),\n",
       " (0.017241379310344827, 'B0002GO8QY'),\n",
       " (0.017094017094017096, 'B00GZ5FCVG'),\n",
       " (0.017094017094017096, 'B0052745WK'),\n",
       " (0.01694915254237288, 'B001G43G96'),\n",
       " (0.01694915254237288, 'B000KITQKM'),\n",
       " (0.016666666666666666, 'B001DL6W0W')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "query=reg_dataset[0]['product_id']\n",
    "itemNames[query]\n",
    "mostSimilar(query,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most similar entries to the first entry in the dataset are: \n",
      " ['Pedaltrain Pro With Soft Case', 'Joyo JF-14 American Sound Effects Pedal Amplifier Simulation with Voice Control', 'Ernie Ball Nickel Plain Single Guitar String .010 6-Pack', 'ISP Technologies Decimator II Noise Reduction Pedal - (New)', 'SKB SKB-FS6 Molded Electric Guitar Case', 'Electro-Harmonix Nano Big Muff Guitar Distortion Effects Pedal', 'Snark SA-2 5 Pedal Daisy Chain', 'K & M Microphone Bar', 'BEHRINGER PREAMP/BOOSTER PB100', 'BBE Supa Charger 8 Output High Performance Power Supply']\n"
     ]
    }
   ],
   "source": [
    "similarprods=[]\n",
    "for x,y in mostSimilar(query,10):\n",
    "    similarprods.append(itemNames[y])\n",
    "print('10 most similar entries to the first entry in the dataset are: \\n',similarprods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished!\n",
    "\n",
    "Congratulations! You are now ready to submit your work. Once you have submitted make sure to get started on your peer reviews!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
